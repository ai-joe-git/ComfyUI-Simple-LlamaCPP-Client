[project]
name = "ComfyUI-Simple-LlamaCPP-Client"
description = "A lightweight custom node for **ComfyUI** that connects to a local **llama.cpp OpenAI-compatible server** with support for chat, vision, streaming, JSON mode, and clean answer/thinking separation."
version = "1.0.0"
requires-python = ">=3.9"
license = { file = "LICENSE" }

dependencies = [
  "requests",
  "pillow"
]

[project.urls]
Repository = "https://github.com/ai-joe-git/ComfyUI-Simple-LlamaCPP-Client"

[tool.comfy]
PublisherId = "ai-joe-git"
DisplayName = "Simple LlamaCPP Client"
Icon = ""
